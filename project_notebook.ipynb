{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "# Capstone Project - Eng. Murilo Biss\n",
    "### Data Engineering Capstone Project\n",
    "\n",
    "#### Project Summary\n",
    "\n",
    "The project follows the follow steps:\n",
    "* Step 1: Scope the Project and Gather Data\n",
    "* Step 2: Explore and Assess the Data\n",
    "* Step 3: Define the Data Model\n",
    "* Step 4: Run ETL to Model the Data\n",
    "* Step 5: Complete Project Write Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Do all imports and installs here\n",
    "import pandas as pd\n",
    "\n",
    "pd.set_option('display.max_colwidth', 1)\n",
    "pd.set_option('display.max_columns', 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 1: Scope the Project and Gather Data\n",
    "\n",
    "#### Scope \n",
    "Explain what you plan to do in the project in more detail. What data do you use? What is your end solution look like? What tools did you use? etc>\n",
    "\n",
    "#### Describe and Gather Data \n",
    "Describe the data sets you're using. Where did it come from? What type of information is included? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Read in the data here\n",
    "fname = 'data/immigration_data_sample.csv'\n",
    "df = pd.read_csv(fname, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1000 entries, 4084316 to 4654865\n",
      "Data columns (total 27 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   i94yr     1000 non-null   int64  \n",
      " 1   i94mon    1000 non-null   int64  \n",
      " 2   i94cit    1000 non-null   int64  \n",
      " 3   i94res    1000 non-null   int64  \n",
      " 4   i94port   1000 non-null   object \n",
      " 5   arrdate   1000 non-null   int64  \n",
      " 6   i94mode   1000 non-null   int64  \n",
      " 7   i94addr   941 non-null    object \n",
      " 8   depdate   951 non-null    float64\n",
      " 9   i94bir    1000 non-null   int64  \n",
      " 10  i94visa   1000 non-null   int64  \n",
      " 11  count     1000 non-null   int64  \n",
      " 12  dtadfile  1000 non-null   int64  \n",
      " 13  visapost  382 non-null    object \n",
      " 14  occup     4 non-null      object \n",
      " 15  entdepa   1000 non-null   object \n",
      " 16  entdepd   954 non-null    object \n",
      " 17  entdepu   0 non-null      float64\n",
      " 18  matflag   954 non-null    object \n",
      " 19  biryear   1000 non-null   int64  \n",
      " 20  dtaddto   1000 non-null   object \n",
      " 21  gender    859 non-null    object \n",
      " 22  insnum    35 non-null     float64\n",
      " 23  airline   967 non-null    object \n",
      " 24  admnum    1000 non-null   int64  \n",
      " 25  fltno     992 non-null    object \n",
      " 26  visatype  1000 non-null   object \n",
      "dtypes: float64(3), int64(12), object(12)\n",
      "memory usage: 218.8+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/08/29 15:43:49 WARN Utils: Your hostname, crislaine resolves to a loopback address: 127.0.1.1; using 192.168.0.110 instead (on interface wlo1)\n",
      "22/08/29 15:43:49 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      ":: loading settings :: url = jar:file:/opt/spark/jars/ivy-2.5.0.jar!/org/apache/ivy/core/settings/ivysettings.xml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ivy Default Cache set to: /home/crislaine/.ivy2/cache\n",
      "The jars for the packages stored in: /home/crislaine/.ivy2/jars\n",
      "saurfang#spark-sas7bdat added as a dependency\n",
      ":: resolving dependencies :: org.apache.spark#spark-submit-parent-edad58f9-37fa-4e91-a351-28c9111d080d;1.0\n",
      "\tconfs: [default]\n",
      "\tfound saurfang#spark-sas7bdat;2.0.0-s_2.11 in spark-packages\n",
      "\tfound com.epam#parso;2.0.8 in central\n",
      "\tfound org.slf4j#slf4j-api;1.7.5 in central\n",
      "\tfound org.apache.logging.log4j#log4j-api-scala_2.11;2.7 in central\n",
      "\tfound org.scala-lang#scala-reflect;2.11.8 in central\n",
      "downloading https://repos.spark-packages.org/saurfang/spark-sas7bdat/2.0.0-s_2.11/spark-sas7bdat-2.0.0-s_2.11.jar ...\n",
      "\t[SUCCESSFUL ] saurfang#spark-sas7bdat;2.0.0-s_2.11!spark-sas7bdat.jar (1904ms)\n",
      "downloading https://repo1.maven.org/maven2/com/epam/parso/2.0.8/parso-2.0.8.jar ...\n",
      "\t[SUCCESSFUL ] com.epam#parso;2.0.8!parso.jar (546ms)\n",
      "downloading https://repo1.maven.org/maven2/org/apache/logging/log4j/log4j-api-scala_2.11/2.7/log4j-api-scala_2.11-2.7.jar ...\n",
      "\t[SUCCESSFUL ] org.apache.logging.log4j#log4j-api-scala_2.11;2.7!log4j-api-scala_2.11.jar (764ms)\n",
      "downloading https://repo1.maven.org/maven2/org/slf4j/slf4j-api/1.7.5/slf4j-api-1.7.5.jar ...\n",
      "\t[SUCCESSFUL ] org.slf4j#slf4j-api;1.7.5!slf4j-api.jar (327ms)\n",
      "downloading https://repo1.maven.org/maven2/org/scala-lang/scala-reflect/2.11.8/scala-reflect-2.11.8.jar ...\n",
      "\t[SUCCESSFUL ] org.scala-lang#scala-reflect;2.11.8!scala-reflect.jar (3680ms)\n",
      ":: resolution report :: resolve 11617ms :: artifacts dl 7239ms\n",
      "\t:: modules in use:\n",
      "\tcom.epam#parso;2.0.8 from central in [default]\n",
      "\torg.apache.logging.log4j#log4j-api-scala_2.11;2.7 from central in [default]\n",
      "\torg.scala-lang#scala-reflect;2.11.8 from central in [default]\n",
      "\torg.slf4j#slf4j-api;1.7.5 from central in [default]\n",
      "\tsaurfang#spark-sas7bdat;2.0.0-s_2.11 from spark-packages in [default]\n",
      "\t---------------------------------------------------------------------\n",
      "\t|                  |            modules            ||   artifacts   |\n",
      "\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n",
      "\t---------------------------------------------------------------------\n",
      "\t|      default     |   5   |   5   |   5   |   0   ||   5   |   5   |\n",
      "\t---------------------------------------------------------------------\n",
      ":: retrieving :: org.apache.spark#spark-submit-parent-edad58f9-37fa-4e91-a351-28c9111d080d\n",
      "\tconfs: [default]\n",
      "\t5 artifacts copied, 0 already retrieved (4883kB/17ms)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/08/29 15:44:09 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling o32.load.\n: java.lang.NoClassDefFoundError: scala/Product$class\n\tat com.github.saurfang.sas.spark.SasRelation.<init>(SasRelation.scala:48)\n\tat com.github.saurfang.sas.spark.SasRelation$.apply(SasRelation.scala:42)\n\tat com.github.saurfang.sas.spark.DefaultSource.createRelation(DefaultSource.scala:50)\n\tat com.github.saurfang.sas.spark.DefaultSource.createRelation(DefaultSource.scala:39)\n\tat com.github.saurfang.sas.spark.DefaultSource.createRelation(DefaultSource.scala:27)\n\tat org.apache.spark.sql.execution.datasources.DataSource.resolveRelation(DataSource.scala:350)\n\tat org.apache.spark.sql.DataFrameReader.loadV1Source(DataFrameReader.scala:228)\n\tat org.apache.spark.sql.DataFrameReader.$anonfun$load$2(DataFrameReader.scala:210)\n\tat scala.Option.getOrElse(Option.scala:189)\n\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:210)\n\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:185)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:566)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n\tat java.base/java.lang.Thread.run(Thread.java:829)\nCaused by: java.lang.ClassNotFoundException: scala.Product$class\n\tat java.base/java.net.URLClassLoader.findClass(URLClassLoader.java:476)\n\tat java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:589)\n\tat java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:522)\n\t... 23 more\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m/home/crislaine/GitProjects/project_udacity/Data-Engineering-Capstone-Project/project_notebook.ipynb Cell 6\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/crislaine/GitProjects/project_udacity/Data-Engineering-Capstone-Project/project_notebook.ipynb#W5sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpyspark\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msql\u001b[39;00m \u001b[39mimport\u001b[39;00m SparkSession\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/crislaine/GitProjects/project_udacity/Data-Engineering-Capstone-Project/project_notebook.ipynb#W5sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m spark \u001b[39m=\u001b[39m SparkSession\u001b[39m.\u001b[39mbuilder\u001b[39m.\u001b[39m\\\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/crislaine/GitProjects/project_udacity/Data-Engineering-Capstone-Project/project_notebook.ipynb#W5sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m config(\u001b[39m\"\u001b[39m\u001b[39mspark.jars.packages\u001b[39m\u001b[39m\"\u001b[39m,\u001b[39m\"\u001b[39m\u001b[39msaurfang:spark-sas7bdat:2.0.0-s_2.11\u001b[39m\u001b[39m\"\u001b[39m)\\\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/crislaine/GitProjects/project_udacity/Data-Engineering-Capstone-Project/project_notebook.ipynb#W5sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39m.\u001b[39menableHiveSupport()\u001b[39m.\u001b[39mgetOrCreate()\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/crislaine/GitProjects/project_udacity/Data-Engineering-Capstone-Project/project_notebook.ipynb#W5sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m df_spark \u001b[39m=\u001b[39mspark\u001b[39m.\u001b[39;49mread\u001b[39m.\u001b[39;49mformat(\u001b[39m'\u001b[39;49m\u001b[39mcom.github.saurfang.sas.spark\u001b[39;49m\u001b[39m'\u001b[39;49m)\u001b[39m.\u001b[39;49mload(\u001b[39m'\u001b[39;49m\u001b[39m../../data/18-83510-I94-Data-2016/i94_apr16_sub.sas7bdat\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "File \u001b[0;32m~/GitProjects/A001 - How_/.venv/lib/python3.10/site-packages/pyspark/sql/readwriter.py:177\u001b[0m, in \u001b[0;36mDataFrameReader.load\u001b[0;34m(self, path, format, schema, **options)\u001b[0m\n\u001b[1;32m    175\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptions(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39moptions)\n\u001b[1;32m    176\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(path, \u001b[39mstr\u001b[39m):\n\u001b[0;32m--> 177\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_df(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_jreader\u001b[39m.\u001b[39;49mload(path))\n\u001b[1;32m    178\u001b[0m \u001b[39melif\u001b[39;00m path \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    179\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mtype\u001b[39m(path) \u001b[39m!=\u001b[39m \u001b[39mlist\u001b[39m:\n",
      "File \u001b[0;32m~/GitProjects/A001 - How_/.venv/lib/python3.10/site-packages/py4j/java_gateway.py:1321\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1315\u001b[0m command \u001b[39m=\u001b[39m proto\u001b[39m.\u001b[39mCALL_COMMAND_NAME \u001b[39m+\u001b[39m\\\n\u001b[1;32m   1316\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcommand_header \u001b[39m+\u001b[39m\\\n\u001b[1;32m   1317\u001b[0m     args_command \u001b[39m+\u001b[39m\\\n\u001b[1;32m   1318\u001b[0m     proto\u001b[39m.\u001b[39mEND_COMMAND_PART\n\u001b[1;32m   1320\u001b[0m answer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgateway_client\u001b[39m.\u001b[39msend_command(command)\n\u001b[0;32m-> 1321\u001b[0m return_value \u001b[39m=\u001b[39m get_return_value(\n\u001b[1;32m   1322\u001b[0m     answer, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgateway_client, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtarget_id, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mname)\n\u001b[1;32m   1324\u001b[0m \u001b[39mfor\u001b[39;00m temp_arg \u001b[39min\u001b[39;00m temp_args:\n\u001b[1;32m   1325\u001b[0m     temp_arg\u001b[39m.\u001b[39m_detach()\n",
      "File \u001b[0;32m~/GitProjects/A001 - How_/.venv/lib/python3.10/site-packages/pyspark/sql/utils.py:190\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    188\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdeco\u001b[39m(\u001b[39m*\u001b[39ma: Any, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkw: Any) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Any:\n\u001b[1;32m    189\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 190\u001b[0m         \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39;49ma, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkw)\n\u001b[1;32m    191\u001b[0m     \u001b[39mexcept\u001b[39;00m Py4JJavaError \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    192\u001b[0m         converted \u001b[39m=\u001b[39m convert_exception(e\u001b[39m.\u001b[39mjava_exception)\n",
      "File \u001b[0;32m~/GitProjects/A001 - How_/.venv/lib/python3.10/site-packages/py4j/protocol.py:326\u001b[0m, in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    324\u001b[0m value \u001b[39m=\u001b[39m OUTPUT_CONVERTER[\u001b[39mtype\u001b[39m](answer[\u001b[39m2\u001b[39m:], gateway_client)\n\u001b[1;32m    325\u001b[0m \u001b[39mif\u001b[39;00m answer[\u001b[39m1\u001b[39m] \u001b[39m==\u001b[39m REFERENCE_TYPE:\n\u001b[0;32m--> 326\u001b[0m     \u001b[39mraise\u001b[39;00m Py4JJavaError(\n\u001b[1;32m    327\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mAn error occurred while calling \u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m{1}\u001b[39;00m\u001b[39m{2}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39m\n\u001b[1;32m    328\u001b[0m         \u001b[39mformat\u001b[39m(target_id, \u001b[39m\"\u001b[39m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m, name), value)\n\u001b[1;32m    329\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    330\u001b[0m     \u001b[39mraise\u001b[39;00m Py4JError(\n\u001b[1;32m    331\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mAn error occurred while calling \u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m{1}\u001b[39;00m\u001b[39m{2}\u001b[39;00m\u001b[39m. Trace:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{3}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39m\n\u001b[1;32m    332\u001b[0m         \u001b[39mformat\u001b[39m(target_id, \u001b[39m\"\u001b[39m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m, name, value))\n",
      "\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling o32.load.\n: java.lang.NoClassDefFoundError: scala/Product$class\n\tat com.github.saurfang.sas.spark.SasRelation.<init>(SasRelation.scala:48)\n\tat com.github.saurfang.sas.spark.SasRelation$.apply(SasRelation.scala:42)\n\tat com.github.saurfang.sas.spark.DefaultSource.createRelation(DefaultSource.scala:50)\n\tat com.github.saurfang.sas.spark.DefaultSource.createRelation(DefaultSource.scala:39)\n\tat com.github.saurfang.sas.spark.DefaultSource.createRelation(DefaultSource.scala:27)\n\tat org.apache.spark.sql.execution.datasources.DataSource.resolveRelation(DataSource.scala:350)\n\tat org.apache.spark.sql.DataFrameReader.loadV1Source(DataFrameReader.scala:228)\n\tat org.apache.spark.sql.DataFrameReader.$anonfun$load$2(DataFrameReader.scala:210)\n\tat scala.Option.getOrElse(Option.scala:189)\n\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:210)\n\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:185)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:566)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n\tat java.base/java.lang.Thread.run(Thread.java:829)\nCaused by: java.lang.ClassNotFoundException: scala.Product$class\n\tat java.base/java.net.URLClassLoader.findClass(URLClassLoader.java:476)\n\tat java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:589)\n\tat java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:522)\n\t... 23 more\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.\\\n",
    "config(\"spark.jars.packages\",\"saurfang:spark-sas7bdat:2.0.0-s_2.11\")\\\n",
    ".enableHiveSupport().getOrCreate()\n",
    "df_spark =spark.read.format('com.github.saurfang.sas.spark').load('../../data/18-83510-I94-Data-2016/i94_apr16_sub.sas7bdat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "#write to parquet\n",
    "#df_spark.write.parquet(\"sas_data\")\n",
    "df_spark=spark.read.parquet(\"data/sas_data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#df_spark.show(2)\n",
    "df_spark.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data contains codes for airports all over the world\n",
    "df_airport = pd.read_csv('data/airport-codes_csv.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ident</th>\n",
       "      <th>type</th>\n",
       "      <th>name</th>\n",
       "      <th>elevation_ft</th>\n",
       "      <th>continent</th>\n",
       "      <th>iso_country</th>\n",
       "      <th>iso_region</th>\n",
       "      <th>municipality</th>\n",
       "      <th>gps_code</th>\n",
       "      <th>iata_code</th>\n",
       "      <th>local_code</th>\n",
       "      <th>coordinates</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>55070</th>\n",
       "      <td>ZYYK</td>\n",
       "      <td>medium_airport</td>\n",
       "      <td>Yingkou Lanqi Airport</td>\n",
       "      <td>0.0</td>\n",
       "      <td>AS</td>\n",
       "      <td>CN</td>\n",
       "      <td>CN-21</td>\n",
       "      <td>Yingkou</td>\n",
       "      <td>ZYYK</td>\n",
       "      <td>YKH</td>\n",
       "      <td>NaN</td>\n",
       "      <td>122.3586, 40.542524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55071</th>\n",
       "      <td>ZYYY</td>\n",
       "      <td>medium_airport</td>\n",
       "      <td>Shenyang Dongta Airport</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AS</td>\n",
       "      <td>CN</td>\n",
       "      <td>CN-21</td>\n",
       "      <td>Shenyang</td>\n",
       "      <td>ZYYY</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>123.49600219726562, 41.784400939941406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55072</th>\n",
       "      <td>ZZ-0001</td>\n",
       "      <td>heliport</td>\n",
       "      <td>Sealand Helipad</td>\n",
       "      <td>40.0</td>\n",
       "      <td>EU</td>\n",
       "      <td>GB</td>\n",
       "      <td>GB-ENG</td>\n",
       "      <td>Sealand</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.4825, 51.894444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55073</th>\n",
       "      <td>ZZ-0002</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Glorioso Islands Airstrip</td>\n",
       "      <td>11.0</td>\n",
       "      <td>AF</td>\n",
       "      <td>TF</td>\n",
       "      <td>TF-U-A</td>\n",
       "      <td>Grande Glorieuse</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>47.296388888900005, -11.584277777799999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55074</th>\n",
       "      <td>ZZZZ</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Satsuma IÅjima Airport</td>\n",
       "      <td>338.0</td>\n",
       "      <td>AS</td>\n",
       "      <td>JP</td>\n",
       "      <td>JP-46</td>\n",
       "      <td>Mishima-Mura</td>\n",
       "      <td>RJX7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>130.270556, 30.784722</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         ident            type                       name  elevation_ft  \\\n",
       "55070  ZYYK     medium_airport  Yingkou Lanqi Airport      0.0            \n",
       "55071  ZYYY     medium_airport  Shenyang Dongta Airport   NaN             \n",
       "55072  ZZ-0001  heliport        Sealand Helipad            40.0           \n",
       "55073  ZZ-0002  small_airport   Glorioso Islands Airstrip  11.0           \n",
       "55074  ZZZZ     small_airport   Satsuma IÅjima Airport    338.0          \n",
       "\n",
       "      continent iso_country iso_region      municipality gps_code iata_code  \\\n",
       "55070  AS        CN          CN-21      Yingkou           ZYYK     YKH        \n",
       "55071  AS        CN          CN-21      Shenyang          ZYYY     NaN        \n",
       "55072  EU        GB          GB-ENG     Sealand           NaN      NaN        \n",
       "55073  AF        TF          TF-U-A     Grande Glorieuse  NaN      NaN        \n",
       "55074  AS        JP          JP-46      Mishima-Mura      RJX7     NaN        \n",
       "\n",
       "      local_code                              coordinates  \n",
       "55070  NaN        122.3586, 40.542524                      \n",
       "55071  NaN        123.49600219726562, 41.784400939941406   \n",
       "55072  NaN        1.4825, 51.894444                        \n",
       "55073  NaN        47.296388888900005, -11.584277777799999  \n",
       "55074  NaN        130.270556, 30.784722                    "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_airport.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 55075 entries, 0 to 55074\n",
      "Data columns (total 12 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   ident         55075 non-null  object \n",
      " 1   type          55075 non-null  object \n",
      " 2   name          55075 non-null  object \n",
      " 3   elevation_ft  48069 non-null  float64\n",
      " 4   continent     27356 non-null  object \n",
      " 5   iso_country   54828 non-null  object \n",
      " 6   iso_region    55075 non-null  object \n",
      " 7   municipality  49399 non-null  object \n",
      " 8   gps_code      41030 non-null  object \n",
      " 9   iata_code     9189 non-null   object \n",
      " 10  local_code    28686 non-null  object \n",
      " 11  coordinates   55075 non-null  object \n",
      "dtypes: float64(1), object(11)\n",
      "memory usage: 5.0+ MB\n"
     ]
    }
   ],
   "source": [
    "df_airport.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cities= pd.read_csv('data/us-cities-demographics.csv', delimiter =';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City</th>\n",
       "      <th>State</th>\n",
       "      <th>Median Age</th>\n",
       "      <th>Male Population</th>\n",
       "      <th>Female Population</th>\n",
       "      <th>Total Population</th>\n",
       "      <th>Number of Veterans</th>\n",
       "      <th>Foreign-born</th>\n",
       "      <th>Average Household Size</th>\n",
       "      <th>State Code</th>\n",
       "      <th>Race</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Silver Spring</td>\n",
       "      <td>Maryland</td>\n",
       "      <td>33.8</td>\n",
       "      <td>40601.0</td>\n",
       "      <td>41862.0</td>\n",
       "      <td>82463</td>\n",
       "      <td>1562.0</td>\n",
       "      <td>30908.0</td>\n",
       "      <td>2.60</td>\n",
       "      <td>MD</td>\n",
       "      <td>Hispanic or Latino</td>\n",
       "      <td>25924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Quincy</td>\n",
       "      <td>Massachusetts</td>\n",
       "      <td>41.0</td>\n",
       "      <td>44129.0</td>\n",
       "      <td>49500.0</td>\n",
       "      <td>93629</td>\n",
       "      <td>4147.0</td>\n",
       "      <td>32935.0</td>\n",
       "      <td>2.39</td>\n",
       "      <td>MA</td>\n",
       "      <td>White</td>\n",
       "      <td>58723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hoover</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>38.5</td>\n",
       "      <td>38040.0</td>\n",
       "      <td>46799.0</td>\n",
       "      <td>84839</td>\n",
       "      <td>4819.0</td>\n",
       "      <td>8229.0</td>\n",
       "      <td>2.58</td>\n",
       "      <td>AL</td>\n",
       "      <td>Asian</td>\n",
       "      <td>4759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Rancho Cucamonga</td>\n",
       "      <td>California</td>\n",
       "      <td>34.5</td>\n",
       "      <td>88127.0</td>\n",
       "      <td>87105.0</td>\n",
       "      <td>175232</td>\n",
       "      <td>5821.0</td>\n",
       "      <td>33878.0</td>\n",
       "      <td>3.18</td>\n",
       "      <td>CA</td>\n",
       "      <td>Black or African-American</td>\n",
       "      <td>24437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Newark</td>\n",
       "      <td>New Jersey</td>\n",
       "      <td>34.6</td>\n",
       "      <td>138040.0</td>\n",
       "      <td>143873.0</td>\n",
       "      <td>281913</td>\n",
       "      <td>5829.0</td>\n",
       "      <td>86253.0</td>\n",
       "      <td>2.73</td>\n",
       "      <td>NJ</td>\n",
       "      <td>White</td>\n",
       "      <td>76402</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               City          State  Median Age  Male Population  \\\n",
       "0  Silver Spring     Maryland       33.8        40601.0           \n",
       "1  Quincy            Massachusetts  41.0        44129.0           \n",
       "2  Hoover            Alabama        38.5        38040.0           \n",
       "3  Rancho Cucamonga  California     34.5        88127.0           \n",
       "4  Newark            New Jersey     34.6        138040.0          \n",
       "\n",
       "   Female Population  Total Population  Number of Veterans  Foreign-born  \\\n",
       "0  41862.0            82463             1562.0              30908.0        \n",
       "1  49500.0            93629             4147.0              32935.0        \n",
       "2  46799.0            84839             4819.0              8229.0         \n",
       "3  87105.0            175232            5821.0              33878.0        \n",
       "4  143873.0           281913            5829.0              86253.0        \n",
       "\n",
       "   Average Household Size State Code                       Race  Count  \n",
       "0  2.60                    MD         Hispanic or Latino         25924  \n",
       "1  2.39                    MA         White                      58723  \n",
       "2  2.58                    AL         Asian                      4759   \n",
       "3  3.18                    CA         Black or African-American  24437  \n",
       "4  2.73                    NJ         White                      76402  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cities.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country_code</th>\n",
       "      <th>country_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>582</td>\n",
       "      <td>MEXICO Air Sea, and Not Reported (I-94, no land arrivals)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>236</td>\n",
       "      <td>AFGHANISTAN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>101</td>\n",
       "      <td>ALBANIA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>316</td>\n",
       "      <td>ALGERIA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>102</td>\n",
       "      <td>ANDORRA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>324</td>\n",
       "      <td>ANGOLA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>529</td>\n",
       "      <td>ANGUILLA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>518</td>\n",
       "      <td>ANTIGUA-BARBUDA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>687</td>\n",
       "      <td>ARGENTINA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>151</td>\n",
       "      <td>ARMENIA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>532</td>\n",
       "      <td>ARUBA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>438</td>\n",
       "      <td>AUSTRALIA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>103</td>\n",
       "      <td>AUSTRIA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>152</td>\n",
       "      <td>AZERBAIJAN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>512</td>\n",
       "      <td>BAHAMAS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    country_code                                               country_name\n",
       "0   582           MEXICO Air Sea, and Not Reported (I-94, no land arrivals)\n",
       "1   236           AFGHANISTAN                                              \n",
       "2   101           ALBANIA                                                  \n",
       "3   316           ALGERIA                                                  \n",
       "4   102           ANDORRA                                                  \n",
       "5   324           ANGOLA                                                   \n",
       "6   529           ANGUILLA                                                 \n",
       "7   518           ANTIGUA-BARBUDA                                          \n",
       "8   687           ARGENTINA                                                \n",
       "9   151           ARMENIA                                                  \n",
       "10  532           ARUBA                                                    \n",
       "11  438           AUSTRALIA                                                \n",
       "12  103           AUSTRIA                                                  \n",
       "13  152           AZERBAIJAN                                               \n",
       "14  512           BAHAMAS                                                  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_country_code = pd.read_csv('data/country_code.csv')\n",
    "df_country_code.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>airport_code</th>\n",
       "      <th>airport_name</th>\n",
       "      <th>airport_state_or_country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ALC</td>\n",
       "      <td>ALCAN</td>\n",
       "      <td>AK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ANC</td>\n",
       "      <td>ANCHORAGE</td>\n",
       "      <td>AK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BAR</td>\n",
       "      <td>BAKER AAF - BAKER ISLAND</td>\n",
       "      <td>AK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DAC</td>\n",
       "      <td>DALTONS CACHE</td>\n",
       "      <td>AK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PIZ</td>\n",
       "      <td>DEW STATION PT LAY DEW</td>\n",
       "      <td>AK</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  airport_code              airport_name airport_state_or_country\n",
       "0  ALC          ALCAN                     AK                     \n",
       "1  ANC          ANCHORAGE                 AK                     \n",
       "2  BAR          BAKER AAF - BAKER ISLAND  AK                     \n",
       "3  DAC          DALTONS CACHE             AK                     \n",
       "4  PIZ          DEW STATION PT LAY DEW    AK                     "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_airport_code = pd.read_csv('data/i94port.csv')\n",
    "df_airport_code.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>i94_mode</th>\n",
       "      <th>transportation_mode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Air</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Sea</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Land</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>Not reported</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   i94_mode transportation_mode\n",
       "0  1         Air               \n",
       "1  2         Sea               \n",
       "2  3         Land              \n",
       "3  9         Not reported      "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_trans_mode = pd.read_csv('data/i94mode.csv')\n",
    "df_trans_mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state_code</th>\n",
       "      <th>state_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AL</td>\n",
       "      <td>ALABAMA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AK</td>\n",
       "      <td>ALASKA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AZ</td>\n",
       "      <td>ARIZONA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AR</td>\n",
       "      <td>ARKANSAS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CA</td>\n",
       "      <td>CALIFORNIA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  state_code  state_name\n",
       "0  AL         ALABAMA   \n",
       "1  AK         ALASKA    \n",
       "2  AZ         ARIZONA   \n",
       "3  AR         ARKANSAS  \n",
       "4  CA         CALIFORNIA"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_state_code = pd.read_csv('data/state_code.csv')\n",
    "df_state_code.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>i94_visa</th>\n",
       "      <th>visa_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Pleasure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Student</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   i94_visa visa_type\n",
       "0  1         Business\n",
       "1  2         Pleasure\n",
       "2  3         Student "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_visa = pd.read_csv('data/visa_type.csv')\n",
    "df_visa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 2: Explore and Assess the Data\n",
    "#### Explore the Data \n",
    "Identify data quality issues, like missing values, duplicate data, etc.\n",
    "\n",
    "#### Cleaning Steps\n",
    "Document steps necessary to clean the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Roll up city data into states and convert some columns into fractions of total population\n",
    "\n",
    "df_states = df_cities.groupby(\"State Code\").agg({\"Median Age\": \"mean\",\n",
    "                                     \"Male Population\": \"sum\",\n",
    "                                     \"Female Population\": \"sum\",\n",
    "                                     \"Total Population\": \"sum\",\n",
    "                                     \"Number of Veterans\": \"sum\",\n",
    "                                     \"Foreign-born\": \"sum\",\n",
    "                                     \"Average Household Size\": \"mean\",\n",
    "                                     \"Count\": \"count\"})\n",
    "\n",
    "# Convert summed values into fraction of total population\n",
    "df_states[\"Male Population\"] = df_states[\"Male Population\"]/df_states[\"Total Population\"]\n",
    "df_states[\"Female Population\"] = df_states[\"Female Population\"]/df_states[\"Total Population\"]\n",
    "df_states[\"Number of Veterans\"] = df_states[\"Number of Veterans\"]/df_states[\"Total Population\"]\n",
    "df_states[\"Foreign-born\"] = df_states[\"Foreign-born\"]/df_states[\"Total Population\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join df_states with df_state_code\n",
    "df_joined_states = df_state_code.join(df_states, how='left', on='state_code')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join df_states with df_state_code\n",
    "df_joined_states = df_state_code.join(df_states, how='left', on='state_code')\n",
    "# Create a new csv file with states data\n",
    "df_joined_states.to_csv('data/us_states.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 55 entries, 0 to 54\n",
      "Data columns (total 10 columns):\n",
      " #   Column                  Non-Null Count  Dtype  \n",
      "---  ------                  --------------  -----  \n",
      " 0   state_code              55 non-null     object \n",
      " 1   state_name              55 non-null     object \n",
      " 2   Median Age              49 non-null     float64\n",
      " 3   Male Population         49 non-null     float64\n",
      " 4   Female Population       49 non-null     float64\n",
      " 5   Total Population        49 non-null     float64\n",
      " 6   Number of Veterans      49 non-null     float64\n",
      " 7   Foreign-born            49 non-null     float64\n",
      " 8   Average Household Size  48 non-null     float64\n",
      " 9   Count                   49 non-null     float64\n",
      "dtypes: float64(8), object(2)\n",
      "memory usage: 4.4+ KB\n"
     ]
    }
   ],
   "source": [
    "df_joined_states.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 3: Define the Data Model\n",
    "#### 3.1 Conceptual Data Model\n",
    "Map out the conceptual data model and explain why you chose that model\n",
    "\n",
    "#### 3.2 Mapping Out Data Pipelines\n",
    "List the steps necessary to pipeline the data into the chosen data model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 4: Run Pipelines to Model the Data \n",
    "#### 4.1 Create the data model\n",
    "Build the data pipelines to create the data model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "####################################################\n",
    "## SQL Queries to build tables in Redshift#########\n",
    "\n",
    "create_tables= (\"\"\"\n",
    "CREATE TABLE IF NOT EXISTS public.staging_immigration (\n",
    "     cicid FLOAT,\n",
    "     i94yr FLOAT,\n",
    "     i94mon FLOAT,\n",
    "     i94cit FLOAT,\n",
    "     i94res FLOAT,\n",
    "     i94port VARCHAR,\n",
    "     arrdate FLOAT,\n",
    "     i94mode FLOAT,\n",
    "     i94addr VARCHAR,\n",
    "     depdate FLOAT,\n",
    "     i94bir FLOAT,\n",
    "     i94visa FLOAT,\n",
    "     count FLOAT,\n",
    "     dtadfile VARCHAR,\n",
    "     visapost VARCHAR,\n",
    "     occup VARCHAR,\n",
    "     entdepa VARCHAR,\n",
    "     entdepd VARCHAR,\n",
    "     entdepu VARCHAR,\n",
    "     matflag VARCHAR,\n",
    "     biryear FLOAT,\n",
    "     dtaddto VARCHAR,\n",
    "     gender VARCHAR,\n",
    "     insnum VARCHAR,\n",
    "     airline VARCHAR,\n",
    "     admnum FLOAT,\n",
    "     fltno VARCHAR,\n",
    "     visatype VARCHAR\n",
    ");\n",
    "     \n",
    "CREATE TABLE IF NOT EXISTS public.states (\n",
    "     state_code VARCHAR,\n",
    "     state_name VARCHAR,\n",
    "     median_age FLOAT,\n",
    "     male_population FLOAT,\n",
    "     female_population FLOAT,\n",
    "     total_population INTEGER,\n",
    "     number_of_veterans FLOAT,\n",
    "     foreign_born FLOAT,\n",
    "     household_size FLOAT,\n",
    "     city_count INTEGER,\n",
    "     CONSTRAINT states_pkey PRIMARY KEY (state_code)\n",
    ");\n",
    "     \n",
    "CREATE TABLE IF NOT EXISTS public.airport_code (\n",
    "     airport_code VARCHAR,\n",
    "     airport_name VARCHAR,\n",
    "     airport_state VARCHAR,\n",
    "     CONSTRAINT airport_pkey PRIMARY KEY (airport_code)\n",
    ");    \n",
    "     \n",
    "CREATE TABLE IF NOT EXISTS public.countries (\n",
    "     country_code VARCHAR,\n",
    "     country_name VARCHAR,\n",
    "     CONSTRAINT countries_pkey PRIMARY KEY (country_code)\n",
    "); \n",
    "\n",
    "CREATE TABLE IF NOT EXISTS public.staging_trans_mode (\n",
    "     i94_mode INTEGER,\n",
    "     transportation_mode VARCHAR,\n",
    "     CONSTRAINT trans_mode_pkey PRIMARY KEY (i94_mode)\n",
    "); \n",
    "     \n",
    "CREATE TABLE IF NOT EXISTS public.staging_visa_code (\n",
    "     i94_visa INTEGER,\n",
    "     visa_type VARCHAR,\n",
    "     CONSTRAINT visa_pkey PRIMARY KEY (i94_visa)\n",
    "); \n",
    "     \n",
    "CREATE TABLE IF NOT EXISTS public.arrivals (\n",
    "     cicid INTEGER,\n",
    "     state_code INTEGER,\n",
    "     country_code INTEGER,\n",
    "     airport_code VARCHAR,\n",
    "     arrdate INTEGER,\n",
    "     arrival_code VARCHAR,\n",
    "     arrival_mode VARCHAR,\n",
    "     state VARCHAR,\n",
    "     airline VARCHAR,\n",
    "     admnum BIGINT,\n",
    "     fltno VARCHAR\n",
    ");\n",
    "     \n",
    "CREATE TABLE IF NOT EXISTS public.admissions (\n",
    "     admnum BIGINT,\n",
    "     gender VARCHAR,\n",
    "     age VARCHAR,\n",
    "     biryear TIMESTAMP,\n",
    "     visa_code INTEGER,\n",
    "     visa_type VARCHAR,\n",
    "     CONSTRAINT admissions_pkey PRIMARY KEY (admnum)\n",
    ");\n",
    "\n",
    "CREATE TABLE IF NOT EXISTS public.time (\n",
    "    arrdate TIMESTAMP,\n",
    "    month int4,\n",
    "    year int4,\n",
    "    week int4,\n",
    "    day int4,\n",
    "    weekday int4,\n",
    "    CONSTRAINT time_pkey PRIMARY KEY (arrdate)\n",
    ");\n",
    "\"\"\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################################\n",
    "## SQL Queries to copy csv tables into Redshift#####\n",
    "\n",
    "copy_sql = \"\"\"\n",
    "COPY {}\n",
    "FROM '{}'\n",
    "ACCESS_KEY_ID '{}'\n",
    "SECRET_ACCESS_KEY '{}'\n",
    "IGNOREHEADER 1\n",
    "CSV;\n",
    "\"\"\"\n",
    "\n",
    "########################################################\n",
    "## SQL Queries to copy parquet tables into Redshift#####\n",
    "\n",
    "copy_parquet_sql = \"\"\"\n",
    "COPY {}\n",
    "FROM '{}'\n",
    "IAM_ROLE '{}'\n",
    "FORMAT AS PARQUET;\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################\n",
    "## SQL Queries to insert tables into Redshift#####\n",
    "        \n",
    "arrivals_table_insert = (\"\"\"\n",
    "SELECT CAST(im.cicid AS INT),\n",
    "       CAST(im.i94cit AS INT) AS state_code,\n",
    "       CAST(im.i94res AS INT) AS country_code,\n",
    "       im.i94port AS airport_code,\n",
    "       CAST(arrdate AS INT),\n",
    "       CAST(im.i94mode AS INT) AS arrival_code,\n",
    "       tm.transportation_mode AS arrival_mode,\n",
    "       im.i94addr AS state,\n",
    "       im.airline,\n",
    "       CAST(im.admnum AS BIGINT),\n",
    "       im.fltno\n",
    "    FROM staging_immigration AS im\n",
    "    LEFT JOIN staging_trans_mode AS tm\n",
    "    ON CAST(im.i94mode AS INT) = tm.i94_mode\n",
    "\"\"\")\n",
    "\n",
    "admissions_table_insert = (\"\"\"\n",
    "SELECT CAST(im.admnum AS BIGINT),\n",
    "       im.gender,\n",
    "       CAST(im.i94bir AS INT),\n",
    "       to_timestamp(CAST(im.biryear AS INT), 'YYYY') as birth_year,\n",
    "       CAST(im.i94visa AS INT),\n",
    "       vs.visa_type\n",
    "    FROM staging_immigration AS im\n",
    "    LEFT JOIN staging_visa_code AS vs\n",
    "    ON CAST(im.i94visa AS INT) = vs.visa_type\n",
    "\"\"\")\n",
    "\n",
    "time_table_insert = (\"\"\"\n",
    "SELECT dates.arrtime AS arrdate,\n",
    "       extract(year from dates.arrtime),\n",
    "       extract(month from dates.arrtime),\n",
    "       extract(week from dates.arrtime), \n",
    "       extract(day from dates.arrtime),\n",
    "       extract(dayofweek from dates.arrtime) AS weekday\n",
    "    FROM (SELECT DATEADD(day, CAST(arrdate AS INT), '1900-01-01') AS arrtime\n",
    "        FROM staging_immigration) dates\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 4.2 Data Quality Checks\n",
    "Explain the data quality checks you'll perform to ensure the pipeline ran as expected. These could include:\n",
    " * Integrity constraints on the relational database (e.g., unique key, data type, etc.)\n",
    " * Unit tests for the scripts to ensure they are doing the right thing\n",
    " * Source/Count checks to ensure completeness\n",
    " \n",
    "Run Quality Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Data quality checks to run in SQL\n",
    "data_quality_checks =[\n",
    " {'check_sql': \"SELECT COUNT(*) FROM arrivals WHERE cic_id IS NULL\", 'expected_result':0},   \n",
    " {'check_sql': \"SELECT COUNT(*) FROM admissions WHERE admnum IS NULL\", 'expected_result':0},\n",
    " {'check_sql': \"SELECT COUNT(*) FROM time WHERE arrdate IS NULL\", 'expected_result':0},\n",
    " {'check_sql': \"SELECT COUNT(*) FROM states WHERE state_code IS NULL\", 'expected_result':0},\n",
    " {'check_sql': \"SELECT COUNT(*) FROM states WHERE state_code IS NULL\", 'expected_result':0}\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 4.3 Data dictionary \n",
    "Create a data dictionary for your data model. For each field, provide a brief description of what the data is and where it came from. You can include the data dictionary in the notebook or in a separate file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Step 5: Complete Project Write Up\n",
    "\n",
    "AWS S3 is chosen as the storage platform due to its low cost, high availability, and compatibility with AWS Redshift.\n",
    "\n",
    "Redshift is selected to host the relational table since it allows for easy start-up process, security, and fast scaling. Further, it has an SQL interface and works very well with data stored in AWS S3 (high performance parallel loading).\n",
    "\n",
    "Airflow is selected as the primary technology to schedule and track the workflow in the ETL pipeline. Airflow provides a simple user interface and the ability to monitor tasks and send alerts in case any of the process fails. In addition, Airflow is easily extendable through the use of custom operators, hooks, and sensors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Additional info\n",
    "\n",
    "The database can be updated on a daily basis as there are over 80 million visitors to the United States every year which is roughly 7 million visitors per month or 230,000 visitors per day. This schedule allows for frequent updates while not requiring too much resources (compute and duration) on each update.\n",
    "\n",
    "In the scenario that the data was increased by 100x:\n",
    "\n",
    "    Host the data on multiple clusters of machine and use Spark SQL to leverage the power of distributed computing in order to speed up the data ingestion and processing steps.\n",
    "\n",
    "In the scenario that the data populates a dashboard that must be updated on a daily basis by 7am every day:\n",
    "\n",
    "    Continue to use AirFlow to update the data but will add a service level agreement to ensure that the data processing is completed before the daily deadline. An alert email can be set up to indicate failure along the process to allow early detection.\n",
    "\n",
    "In the scenario that the database needed to be accessed by 100+ people:\n",
    "\n",
    "    Choose a database system that is compatible with Spark as Spark has powerful built-in tools to handle concurrent operations by scheduling work in a sequential manner while still enabling parallelism."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "b61c11f19483c64484dd252a245bb56ad71287c75fe9dfb6ebba97d4494af45b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
